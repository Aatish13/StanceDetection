{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Read our dataset, and seperate based on labels. \n",
    "# When user gives tweet, we compare each word in the tweet\n",
    "# to the corresponding dataframe and see what words are that dataframe\n",
    "# In order to make sure we are not including non-important words, preprocess is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['believer' 'denier' 'neutral']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>stance</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>believer</td>\n",
       "      <td>unenvironment never able tackle climate change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.070000e+18</td>\n",
       "      <td>believer</td>\n",
       "      <td>oxfam many people need die drought induced hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.920000e+17</td>\n",
       "      <td>believer</td>\n",
       "      <td>pakistani city breaks april record day 50c hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.130000e+18</td>\n",
       "      <td>believer</td>\n",
       "      <td>meet christopher lee ceo climate kic aus speak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>believer</td>\n",
       "      <td>mariansmedley would like see every article rep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    stance                                              Tweet\n",
       "0  1.050000e+18  believer  unenvironment never able tackle climate change...\n",
       "1  1.070000e+18  believer  oxfam many people need die drought induced hun...\n",
       "2  9.920000e+17  believer  pakistani city breaks april record day 50c hea...\n",
       "3  1.130000e+18  believer  meet christopher lee ceo climate kic aus speak...\n",
       "4  1.120000e+18  believer  mariansmedley would like see every article rep..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dataset\n",
    "dataset_df = pd.read_csv(\"../Dataset/Preprocessed_Data_Added_More.csv\")\n",
    "print(dataset_df[\"stance\"].unique())\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unenvironment never able tackle climate change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oxfam many people need die drought induced hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakistani city breaks april record day 50c hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet christopher lee ceo climate kic aus speak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mariansmedley would like see every article rep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  unenvironment never able tackle climate change...\n",
       "1  oxfam many people need die drought induced hun...\n",
       "2  pakistani city breaks april record day 50c hea...\n",
       "3  meet christopher lee ceo climate kic aus speak...\n",
       "4  mariansmedley would like see every article rep..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Dataframe into the corresponding label\n",
    "believer_df = pd.DataFrame(dataset_df[dataset_df[\"stance\"] == \"believer\"][\"Tweet\"])\n",
    "# believer_df.head(5)\n",
    "denier_df = pd.DataFrame(dataset_df[dataset_df[\"stance\"] == \"denier\"][\"Tweet\"])\n",
    "neutral_df = pd.DataFrame(dataset_df[dataset_df[\"stance\"] == \"neutral\"][\"Tweet\"])\n",
    "\n",
    "# Make sure the split is done correctly\n",
    "print(len(believer_df) + len(denier_df) + len(neutral_df) == len(dataset_df))\n",
    "believer_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/check-for-a-substring-in-a-pandas-dataframe-column-4b949f64852\n",
    "# Using Contains we can use the length > 0 to know if the word is in the dataset\n",
    "print(len(believer_df.loc[believer_df['Tweet'].str.contains(\"unenvironment\", case=False)]))\n",
    "print(len(believer_df.loc[believer_df['Tweet'].str.contains(\"unenviXronment\", case=False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unenvironment never able tackle climate change without bringing climate culture india taki\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['unenvironment',\n",
       " 'never',\n",
       " 'able',\n",
       " 'tackle',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'without',\n",
       " 'bringing',\n",
       " 'climate',\n",
       " 'culture',\n",
       " 'india',\n",
       " 'taki']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since this is from dataset every word should be found\n",
    "test_string = believer_df.iloc[0:1,0:1].values[0][0]\n",
    "print(test_string)\n",
    "keywords = []\n",
    "for word in test_string.split(\" \"):\n",
    "    if len(believer_df.loc[believer_df['Tweet'].str.contains(word, case=False)]) > 0:\n",
    "        keywords.append(word)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recovery',\n",
       " 'economic',\n",
       " 'demographic',\n",
       " 'military',\n",
       " 'debt',\n",
       " 'inflation',\n",
       " 'push',\n",
       " 'humans',\n",
       " 'nature',\n",
       " 'wipeout',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'fallout',\n",
       " 'natural',\n",
       " 'disasters',\n",
       " 'wars',\n",
       " 'resources',\n",
       " 'migration',\n",
       " 'amp',\n",
       " 'blame',\n",
       " 'closures',\n",
       " 'russia',\n",
       " 'china',\n",
       " 'amp',\n",
       " 'humans',\n",
       " 'poverty',\n",
       " 'humans',\n",
       " 'alive',\n",
       " 'ago']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test String from the Live Demo CSV\n",
    "test_string = \"\"\"recovery economic demographic military debt inflation push humans nature wipeout climate change fallout natural \n",
    "              disasters wars resources migration amp blame bankruptcies closures russia china amp covid humans poverty humans alive 70yrs ago\"\"\"\n",
    "# print(test_string)\n",
    "keywords = []\n",
    "for word in test_string.split(\" \"):\n",
    "    if len(believer_df.loc[believer_df['Tweet'].str.contains(word, case=False)]) > 0:\n",
    "        keywords.append(word)\n",
    "# Remove this: '' that appeared in the list\n",
    "keywords = [x for x in keywords if len(x.strip()) > 0]\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: 214\n",
      "Original Word: 254\n"
     ]
    }
   ],
   "source": [
    "# Compare the length of keywords to orginal string to see how much keywords were found\n",
    "print(\"Keywords: \" + str(len(\" \".join(keywords))))\n",
    "print(\"Original Word: \" + str(len(test_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comare word with dataframe & return the common words\n",
    "def extract_Keywords(tweet, df):\n",
    "    keywords = []\n",
    "    for word in tweet.split(\" \"):\n",
    "        if len(df.loc[df['Tweet'].str.contains(word, case=False)]) > 0:\n",
    "            keywords.append(word)\n",
    "    # Remove this: '' that appeared in the list\n",
    "    keywords = [x for x in keywords if len(x.strip()) > 0]\n",
    "    return keywords\n",
    "\n",
    "# Get tweet and stancetype to send the correct dataframe to extract_Keywords\n",
    "def getKeywords_fucntion(tweet, stanceType):\n",
    "    keywords = []\n",
    "    if stanceType == \"believer\" or stanceType == 2:\n",
    "        keywords = extract_Keywords(tweet, believer_df)\n",
    "    elif stanceType == \"denier\" or stanceType == 1:\n",
    "        keywords = extract_Keywords(tweet, denier_df)\n",
    "    elif stanceType == \"neutral\" or stanceType == 0:\n",
    "        keywords = extract_Keywords(tweet, neutral_df)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>stance</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.643320e+18</td>\n",
       "      <td>2023-04-04 18:27:48+00:00</td>\n",
       "      <td>recovery economic demographic military debt in...</td>\n",
       "      <td>believer</td>\n",
       "      <td>[recovery, economic, demographic, military, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.643320e+18</td>\n",
       "      <td>2023-04-04 18:27:40+00:00</td>\n",
       "      <td>proudelephantus hellonheels2020 beach mansion ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[beach, mansion, climate, change, hypocrites, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.643320e+18</td>\n",
       "      <td>2023-04-04 18:27:36+00:00</td>\n",
       "      <td>recovery economic demographic military debt in...</td>\n",
       "      <td>believer</td>\n",
       "      <td>[recovery, economic, demographic, military, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.643320e+18</td>\n",
       "      <td>2023-04-04 18:27:31+00:00</td>\n",
       "      <td>evelyn von warnitz added logline titled amazin...</td>\n",
       "      <td>denier</td>\n",
       "      <td>[evelyn, von, added, titled, amazing, life, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.643320e+18</td>\n",
       "      <td>2023-04-04 18:27:22+00:00</td>\n",
       "      <td>royalaviaire reversed climate change</td>\n",
       "      <td>denier</td>\n",
       "      <td>[reversed, climate, change]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            ID                       Date  \\\n",
       "0           0  1.643320e+18  2023-04-04 18:27:48+00:00   \n",
       "1           1  1.643320e+18  2023-04-04 18:27:40+00:00   \n",
       "2           2  1.643320e+18  2023-04-04 18:27:36+00:00   \n",
       "3           3  1.643320e+18  2023-04-04 18:27:31+00:00   \n",
       "4           4  1.643320e+18  2023-04-04 18:27:22+00:00   \n",
       "\n",
       "                                               Tweet    stance  \\\n",
       "0  recovery economic demographic military debt in...  believer   \n",
       "1  proudelephantus hellonheels2020 beach mansion ...   neutral   \n",
       "2  recovery economic demographic military debt in...  believer   \n",
       "3  evelyn von warnitz added logline titled amazin...    denier   \n",
       "4               royalaviaire reversed climate change    denier   \n",
       "\n",
       "                                            Keywords  \n",
       "0  [recovery, economic, demographic, military, de...  \n",
       "1  [beach, mansion, climate, change, hypocrites, ...  \n",
       "2  [recovery, economic, demographic, military, de...  \n",
       "3  [evelyn, von, added, titled, amazing, life, co...  \n",
       "4                        [reversed, climate, change]  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Call for multiple tweets\n",
    "# Note: output.csv is the download file from the server.py\n",
    "test_df = pd.read_csv(\"../LiveDemoDataset/output.csv\")\n",
    "test_df[\"Keywords\"] = test_df.apply(lambda x: getKeywords_fucntion(x['Tweet'], x['stance']), axis=1)\n",
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recovery economic demographic military debt inflation push humans nature wipeout climate change fallout natural \n",
      "              disasters wars resources migration amp blame bankruptcies closures russia china amp covid humans poverty humans alive 70yrs ago\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['recovery',\n",
       " 'economic',\n",
       " 'demographic',\n",
       " 'military',\n",
       " 'debt',\n",
       " 'inflation',\n",
       " 'push',\n",
       " 'humans',\n",
       " 'nature',\n",
       " 'wipeout',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'fallout',\n",
       " 'natural',\n",
       " 'disasters',\n",
       " 'wars',\n",
       " 'resources',\n",
       " 'migration',\n",
       " 'amp',\n",
       " 'blame',\n",
       " 'closures',\n",
       " 'russia',\n",
       " 'china',\n",
       " 'amp',\n",
       " 'humans',\n",
       " 'poverty',\n",
       " 'humans',\n",
       " 'alive',\n",
       " 'ago']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Call for single tweet\n",
    "test_string = \"\"\"recovery economic demographic military debt inflation push humans nature wipeout climate change fallout natural \n",
    "              disasters wars resources migration amp blame bankruptcies closures russia china amp covid humans poverty humans alive 70yrs ago\"\"\"\n",
    "getKeywords_fucntion(test_string, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
